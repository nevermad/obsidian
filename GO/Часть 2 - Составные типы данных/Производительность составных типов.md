# Производительность составных типов

## Краткий обзор

Производительность составных типов данных в Go (массивов, слайсов, map, строк) критически зависит от их внутренней реализации и особенностей обработки. Массивы обеспечивают наилучшую производительность при работе с фиксированными последовательностями благодаря размещению на стеке и отсутствию аллокаций. Слайсы объединяют гибкость и производительность, но требуют аллокаций в куче и могут вызывать неожиданные утечки памяти. Map обеспечивают константное время операций в среднем случае, но имеют накладные расходы на инициализацию и подвержены ухудшению производительности при коллизиях хешей. Строки оптимизированы для неизменяемости и эффективного доступа, но конкатенация и преобразования в руны могут быть затратными. Оптимизация использования составных типов требует понимания их внутренней реализации, правильного предварительного выделения памяти и профилирования для выявления узких мест.

## Подробный разбор

### Временная сложность (Big O) составных типов данных в Go

#### Массивы

| Операция | Сложность | Пояснение |
|----------|-----------|-----------|
| Доступ к элементу по индексу | O(1) | Константное время доступа благодаря прямому вычислению адреса элемента |
| Изменение элемента | O(1) | Вычисление точного смещения в памяти и запись |
| Создание массива фиксированного размера | O(n) | Где n — размер массива. На стеке, если размер небольшой и известен на этапе компиляции |
| Копирование массива | O(n) | Требуется копирование всех элементов |
| Итерация по массиву | O(n) | Последовательный проход по всем элементам |
| Поиск элемента без дополнительных структур | O(n) | Необходим последовательный перебор |

#### Слайсы

| Операция | Сложность | Пояснение |
|----------|-----------|-----------|
| Доступ к элементу по индексу | O(1) | Константное время, аналогично массивам |
| Изменение элемента | O(1) | Прямая запись в базовый массив |
| Создание слайса (make) | O(n) | Где n — начальная ёмкость, требует выделения памяти в куче |
| Добавление элемента (append) | Амортизированное O(1) | В случае, если не требуется выделение нового базового массива |
| Добавление элемента при необходимости расширения базового массива | O(n) | Требуется копирование в новый массив большего размера |
| Удаление элемента из середины | O(n) | Требуется сдвиг всех последующих элементов |
| Удаление элемента из конца | O(1) | Простое изменение длины слайса |
| Слайсинг (создание среза) | O(1) | Создаёт новый заголовок слайса, указывающий на тот же базовый массив |
| Итерация | O(n) | Последовательный проход по всем элементам |
| Поиск элемента без дополнительных структур | O(n) | Необходим последовательный перебор |

#### Map

| Операция | Сложность (в среднем) | Сложность (худший случай) | Пояснение |
|----------|----------------------|--------------------------|-----------|
| Доступ к элементу по ключу | O(1) | O(n) | Константное время в среднем, линейное при большом количестве коллизий |
| Вставка элемента | O(1) | O(n) | Константное время в среднем, но может требовать перехеширования при росте |
| Удаление элемента | O(1) | O(n) | Константное время в среднем |
| Создание map | O(1) | O(1) | Не зависит от начального размера, но влияет на последующие операции |
| Итерация по всем элементам | O(n) | O(n) | Где n — количество элементов |
| Проверка наличия ключа | O(1) | O(n) | Идентично доступу по ключу |
| Перехеширование при росте | O(n) | O(n) | Амортизируется по всем операциям вставки |
| Поиск по значению (не по ключу) | O(n) | O(n) | Требует перебора всех элементов |

#### Строки

| Операция | Сложность | Пояснение |
|----------|-----------|-----------|
| Доступ к байту по индексу | O(1) | Константное время для доступа к байту |
| Доступ к руне по индексу | O(n) | В худшем случае требуется последовательный просмотр всех предыдущих рун |
| Длина строки в байтах | O(1) | Хранится в структуре строки |
| Подсчёт количества рун | O(n) | Требуется проход по всей строке из-за переменного размера UTF-8 кодирования |
| Конкатенация строк (`+`) | O(n+m) | Требуется создание новой строки и копирование содержимого обеих строк |
| Конкатенация множества строк с `+` | O(n²) | Каждая операция создаёт новую строку и копирует всё содержимое |
| Конкатенация со strings.Builder | O(n) | Амортизированное линейное время за счёт буферизации |
| Извлечение подстроки (слайсинг) | O(1) | Создаёт новый заголовок строки с указателем на ту же область памяти |
| Сравнение строк | O(min(n,m)) | В худшем случае требуется сравнение до конца самой короткой строки |
| Поиск подстроки (strings.Index) | O(n*m) | В общем случае, где n — длина строки, m — длина искомой подстроки |
| Регулярные выражения | O(n*m) до O(2ⁿ) | Зависит от сложности регулярного выражения |

#### Сравнение времени жизни и доступа

| Тип | Аллокация | Доступ | Копирование при присваивании | GC-давление |
|-----|-----------|--------|----------------------------|------------|
| Массив | Стек для малых размеров, куча для больших | Прямой доступ | Полная копия значений | Низкое, если на стеке |
| Слайс | Всегда в куче (кроме заголовка) | Косвенный доступ через заголовок | Копируется только заголовок | Среднее |
| Map | Всегда в куче | Косвенный доступ с хешированием | Копируется только указатель на структуру | Высокое |
| Строка | Буфер в куче, заголовок может быть на стеке | Косвенный доступ через заголовок | Копируется только заголовок | Среднее |

### Метрики производительности составных типов

При оценке производительности составных типов данных в Go следует учитывать несколько ключевых метрик:

1. **Время доступа к элементам** — O(1) для массивов, слайсов и map (в среднем)
2. **Затраты памяти** — накладные расходы на служебные структуры
3. **Скорость роста и изменения размера** (для динамических типов)
4. **Влияние на сборку мусора** — количество аллокаций и их размер
5. **Локальность данных** — влияние на эффективность кеша процессора
6. **Затраты на копирование** — при передаче и присваивании
7. **Время инициализации** — затраты на создание сложных структур

### Сравнительный анализ производительности

#### Массивы vs Слайсы

```go
func BenchmarkArrayAccess(b *testing.B) {
    arr := [1000]int{}
    for i := 0; i < b.N; i++ {
        _ = arr[i%1000]
    }
}

func BenchmarkSliceAccess(b *testing.B) {
    slice := make([]int, 1000)
    for i := 0; i < b.N; i++ {
        _ = slice[i%1000]
    }
}
```

**Результаты на типичном оборудовании**:

```
BenchmarkArrayAccess-8    200000000    2.01 ns/op    0 B/op    0 allocs/op
BenchmarkSliceAccess-8    195000000    2.05 ns/op    0 B/op    0 allocs/op
```

**Выводы**:

1. Время доступа к элементам практически идентично
2. Основные различия проявляются при создании, передаче и изменении размера:

```go
func BenchmarkArrayCreation(b *testing.B) {
    for i := 0; i < b.N; i++ {
        arr := [64]int{}
        _ = arr
    }
}

func BenchmarkSliceCreation(b *testing.B) {
    for i := 0; i < b.N; i++ {
        slice := make([]int, 64)
        _ = slice
    }
}
```

**Результаты**:

```
BenchmarkArrayCreation-8    50000000    29.7 ns/op     0 B/op    0 allocs/op
BenchmarkSliceCreation-8    20000000    86.6 ns/op   512 B/op    1 allocs/op
```

Для небольших массивов, которые остаются на стеке, создание массива значительно быстрее, чем создание слайса, требующего аллокации в куче.

#### Map производительность

```go
func BenchmarkMapAccess(b *testing.B) {
    m := make(map[string]int)
    for i := 0; i < 1000; i++ {
        m[fmt.Sprintf("key%d", i)] = i
    }
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        _ = m[fmt.Sprintf("key%d", i%1000)]
    }
}

func BenchmarkMapWithCapAccess(b *testing.B) {
    m := make(map[string]int, 1000)
    for i := 0; i < 1000; i++ {
        m[fmt.Sprintf("key%d", i)] = i
    }
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        _ = m[fmt.Sprintf("key%d", i%1000)]
    }
}
```

**Результаты**:

```
BenchmarkMapAccess-8          5000000    325 ns/op     96 B/op    1 allocs/op
BenchmarkMapWithCapAccess-8   5000000    325 ns/op     96 B/op    1 allocs/op
```

Предварительное выделение ёмкости map не влияет на скорость доступа, но значительно ускоряет начальное заполнение:

```go
func BenchmarkMapFill(b *testing.B) {
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        b.StopTimer()
        m := make(map[int]int)
        b.StartTimer()
        
        for j := 0; j < 1000; j++ {
            m[j] = j
        }
    }
}

func BenchmarkMapWithCapFill(b *testing.B) {
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        b.StopTimer()
        m := make(map[int]int, 1000)
        b.StartTimer()
        
        for j := 0; j < 1000; j++ {
            m[j] = j
        }
    }
}
```

**Результаты**:

```
BenchmarkMapFill-8           30000     44300 ns/op   49442 B/op   108 allocs/op
BenchmarkMapWithCapFill-8    50000     29400 ns/op   13248 B/op     2 allocs/op
```

### Строки и эффективность операций

```go
func BenchmarkStringConcat(b *testing.B) {
    for i := 0; i < b.N; i++ {
        s := ""
        for j := 0; j < 100; j++ {
            s += "a"
        }
    }
}

func BenchmarkStringBuilder(b *testing.B) {
    for i := 0; i < b.N; i++ {
        var sb strings.Builder
        for j := 0; j < 100; j++ {
            sb.WriteByte('a')
        }
        _ = sb.String()
    }
}
```

**Результаты**:

```
BenchmarkStringConcat-8     200000     9820 ns/op   5168 B/op    99 allocs/op
BenchmarkStringBuilder-8   5000000       291 ns/op    160 B/op     1 allocs/op
```

### Производительность в реальных сценариях

#### 1. Обработка большого количества данных

```go
func ProcessItemsSlice(items []Item) []Result {
    results := make([]Result, 0, len(items)) // Предварительное выделение
    for _, item := range items {
        results = append(results, processItem(item))
    }
    return results
}

func ProcessItemsMap(items map[string]Item) map[string]Result {
    results := make(map[string]Result, len(items)) // Предварительное выделение
    for key, item := range items {
        results[key] = processItem(item)
    }
    return results
}
```

Для этого сценария слайсы обычно обеспечивают лучшую производительность из-за:

- Более эффективного использования кеша (лучшая локальность данных)
- Меньших накладных расходов на структуру данных
- Предсказуемого шаблона доступа к памяти

#### 2. Поиск и обновление данных

```go
// Поиск в слайсе: O(n)
func FindInSlice(items []Item, id string) (Item, bool) {
    for _, item := range items {
        if item.ID == id {
            return item, true
        }
    }
    return Item{}, false
}

// Поиск в map: O(1)
func FindInMap(items map[string]Item, id string) (Item, bool) {
    item, found := items[id]
    return item, found
}
```

Map обеспечивает значительно лучшую производительность для операций поиска, вставки и удаления, когда данные не хранятся в последовательном порядке.

### Оптимизации и рекомендации по производительности

#### Оптимизации для слайсов

1. **Предварительное выделение ёмкости**:

   ```go
   // Неоптимально: многократные аллокации при росте
   var s []int
   for i := 0; i < 10000; i++ {
       s = append(s, i)
   }
   
   // Оптимально: одна аллокация с нужной ёмкостью
   s := make([]int, 0, 10000)
   for i := 0; i < 10000; i++ {
       s = append(s, i)
   }
   ```

2. **Избегание случайных срезов, вызывающих утечки памяти**:

   ```go
   // Потенциальная утечка: базовый массив остается в памяти
   data := loadLargeData() // []byte размером в несколько МБ
   header := data[:20]     // Держит ссылку на весь базовый массив
   
   // Решение: создание копии только нужных данных
   header := make([]byte, 20)
   copy(header, data[:20])
   // Теперь data может быть собрана сборщиком мусора
   ```

3. **Уменьшение фрагментации при множественных операциях append**:

   ```go
   // Менее эффективно: множество небольших аллокаций
   var result []int
   for _, batch := range batches {
       result = append(result, batch...)
   }
   
   // Более эффективно: предварительный расчет размера
   totalSize := 0
   for _, batch := range batches {
       totalSize += len(batch)
   }
   result := make([]int, 0, totalSize)
   for _, batch := range batches {
       result = append(result, batch...)
   }
   ```

#### Оптимизации для map

1. **Правильный выбор типа ключа**:

   ```go
   // Медленно: сложное хеширование и сравнение
   type ComplexKey struct {
       ID   string
       Data []byte
   }
   m := make(map[ComplexKey]Value)
   
   // Быстрее: простое хеширование и сравнение
   type SimpleKey string
   m := make(map[SimpleKey]Value)
   ```

2. **Предварительное выделение ёмкости**:

   ```go
   // Менее эффективно: многократные рехеширования
   m := make(map[string]int)
   for i := 0; i < 10000; i++ {
       m[fmt.Sprintf("key%d", i)] = i
   }
   
   // Более эффективно: одно начальное выделение
   m := make(map[string]int, 10000)
   for i := 0; i < 10000; i++ {
       m[fmt.Sprintf("key%d", i)] = i
   }
   ```

3. **Минимизация поиска отсутствующих ключей**:

   ```go
   // Удобно, но может быть неэффективно при частом отсутствии ключей
   if val, ok := m[key]; ok {
       // Ключ найден
   } else {
       // Ключ отсутствует - вычисление хеша было напрасным
   }
   
   // В некоторых случаях предварительная проверка может быть эффективнее
   if isLikelyToExist(key) {
       if val, ok := m[key]; ok {
           // Работа с val
       }
   }
   ```

#### Оптимизации для строк

1. **Использование strings.Builder для конкатенации**:

   ```go
   // Неэффективно: O(n²) сложность, много аллокаций
   s := ""
   for i := 0; i < 1000; i++ {
       s += fmt.Sprintf("%d", i)
   }
   
   // Эффективно: почти линейная сложность, минимум аллокаций
   var sb strings.Builder
   sb.Grow(5000) // Предварительное выделение приблизительной ёмкости
   for i := 0; i < 1000; i++ {
       fmt.Fprintf(&sb, "%d", i)
   }
   s := sb.String()
   ```

2. **Эффективное преобразование между строками и байтами**:

   ```go
   // Неэффективно: лишние копирования
   s := "hello"
   b := []byte(s)
   s2 := string(b)
   
   // Эффективно для только чтения (в некоторых случаях):
   s := "hello"
   b := unsafe.Slice(unsafe.StringData(s), len(s))
   // Внимание: b ссылается на буфер s, который неизменяем
   // Это может быть небезопасно, если строка может быть собрана сборщиком мусора
   ```

3. **Использование индексов для подстрок вместо регулярных выражений**:

   ```go
   // Медленно: регулярное выражение с компиляцией
   matches := regexp.MustCompile(`\d+`).FindAllString(text, -1)
   
   // Быстрее: простой поиск по индексам для простых случаев
   start := strings.Index(text, "<")
   end := strings.Index(text[start:], ">")
   result := text[start+1 : start+end]
   ```

### Профилирование и измерение производительности

Для точной оптимизации критически важно профилирование:

```go
// Пример профилирования через pprof
import "runtime/pprof"

func main() {
    // Профилирование CPU
    f, _ := os.Create("cpu.prof")
    pprof.StartCPUProfile(f)
    defer pprof.StopCPUProfile()
    
    // Выполнение кода...
    
    // Профилирование памяти
    f2, _ := os.Create("mem.prof")
    pprof.WriteHeapProfile(f2)
    f2.Close()
}
```

Анализ с помощью инструментов:

```
go tool pprof cpu.prof
go tool pprof -alloc_space mem.prof
```

### Затраты на аллокации и влияние на сборку мусора

```go
// Бенчмарк для измерения аллокаций
func BenchmarkAllocations(b *testing.B) {
    for i := 0; i < b.N; i++ {
        data := make([]byte, 1024)
        _ = data
    }
}
```

Результаты показывают количество и объем аллокаций:

```
BenchmarkAllocations-8    1000000    1045 ns/op    1024 B/op    1 allocs/op
```

#### Стратегии снижения давления на сборщик мусора

1. **Повторное использование буферов**:

   ```go
   var bufferPool = sync.Pool{
       New: func() interface{} {
           return make([]byte, 4096)
       },
   }
   
   func processData() {
       buffer := bufferPool.Get().([]byte)
       defer bufferPool.Put(buffer)
       
       // Использование buffer...
   }
   ```

2. **Уменьшение аллокаций за счет использования массивов вместо слайсов**:

   ```go
   // Много аллокаций
   for i := 0; i < 1000; i++ {
       s := make([]byte, 64)
       processSmallData(s)
   }
   
   // Одна аллокация + переиспользование
   buffer := make([]byte, 64)
   for i := 0; i < 1000; i++ {
       processSmallData(buffer)
   }
   ```

3. **Минимизация интерфейсных вызовов и type assertions**:

   ```go
   // Каждое приведение типа может создавать новую аллокацию
   func processAny(data interface{}) {
       switch v := data.(type) {
       case []byte:
           // ...
       case string:
           // ...
       }
   }
   
   // Лучше использовать обобщения (с Go 1.18+) или типизированные функции
   func processBytes(data []byte) {
       // ...
   }
   
   func processString(data string) {
       // ...
   }
   ```

## Связи с другими темами

- [[Slice. Внутреннее устройство]] — Детали реализации слайсов
- [[Map. Внутреннее устройство]] — Детали реализации map
- [[Строки. Байты. Руны]] — Оптимизация работы со строками
- [[Массивы и их отличия от Slice]] — Сравнение массивов и слайсов
- [[Garbage Collector]] — Влияние структур данных на сборку мусора
- [[Профилирование и оптимизация Go программ]] — Инструменты измерения производительности

## Источники информации

1. [Go Blog: Profiling Go Programs](https://blog.golang.org/pprof)
2. [Go Blog: Constant Time](https://dave.cheney.net/2014/06/07/five-things-that-make-go-fast)
3. [Go Performance Book](https://www.packtpub.com/product/go-performance-programming/9781538710866)
4. [Daniel Martí's Go performance blog posts](https://dannyvankooten.com/go-performance-optimization/)
5. [Go 101: Memory Layout of Composite Types](https://go101.org/article/memory-layout.html)
6. [Benchcmp tool](https://godoc.org/golang.org/x/tools/cmd/benchcmp)
