# Ответы: Go Scheduler

## Что представляет собой модель GMP в планировщике Go?

Модель GMP — это основа планировщика Go, которая состоит из трех ключевых компонентов:

1. **G (Goroutine)** — горутина, легковесный поток выполнения с собственным стеком и состоянием. Представляет конкретную задачу, которую нужно выполнить.

2. **M (Machine)** — поток ОС (OS Thread), который фактически выполняет код. Операционная система планирует выполнение этих потоков на физических процессорах.

3. **P (Processor)** — абстракция, обеспечивающая контекст выполнения, который соединяет G и M. Содержит очередь готовых к выполнению горутин и другие ресурсы для планирования.

Взаимосвязь компонентов:

- Поток M может выполнять горутину G только с помощью процессора P
- Для выполнения горутины нужны все три компонента (G, M, P)
- Количество P определяется значением GOMAXPROCS (по умолчанию = количество ядер CPU)
- Количество M динамически адаптируется к нагрузке
- Количество G может достигать миллионов

Модель GMP обеспечивает эффективное многопоточное выполнение горутин с минимальными накладными расходами.

## Какую роль выполняет каждый из компонентов G, M и P?

**G (Goroutine)**:

- Представляет единицу работы, которую нужно выполнить
- Содержит стек (изначально ~2KB, может расти до 1GB)
- Хранит контекст выполнения (счетчик команд, указатели на стек, регистры)
- Включает информацию о блокировке (почему горутина приостановлена)
- Содержит ссылки на каналы, таймеры и другие ресурсы
- Может находиться в разных состояниях: выполнение, ожидание, готовность

**M (Machine)**:

- Является потоком ОС, который фактически выполняет код
- Планируется ОС для выполнения на физических ядрах процессора
- Хранит небольшой кэш для повторного использования ресурсов
- Содержит указатель на текущую горутину и P, с которым связан
- Может быть в состоянии блокировки, выполнения или простоя
- Обрабатывает системные вызовы и cgo-код

**P (Processor)**:

- Обеспечивает контекст выполнения, соединяющий G и M
- Содержит локальную очередь готовых горутин (runqueue)
- Управляет кэшами объектов для аллокатора памяти (mcache)
- Содержит ссылки на планировщик и статистику выполнения
- Обеспечивает изоляцию и минимизирует конкуренцию за ресурсы
- Контролирует ограничение параллелизма (через GOMAXPROCS)

Эта трехкомпонентная модель обеспечивает гибкое планирование, эффективное использование ресурсов и высокую производительность при большом количестве горутин.

## Как соотносится количество P, M и G в типичной Go-программе?

В типичной Go-программе соотношение количества компонентов P, M и G следующее:

**P (Processor)**:

- Количество P равно значению GOMAXPROCS
- По умолчанию GOMAXPROCS равен количеству логических ядер CPU
- Обычно это число фиксировано во время работы программы (если не менять GOMAXPROCS)
- В большинстве случаев от 2 до 32 (в зависимости от количества ядер)

**M (Machine)**:

- Количество активных M обычно близко к количеству P
- Дополнительные M создаются для обработки блокирующих системных вызовов
- Фактическое количество M адаптируется к рабочей нагрузке
- Верхний предел обычно ограничен (по умолчанию 10000, хотя редко достигается)
- Обычно их немного больше, чем P (например, P=8, M=10-12)
- Go пытается повторно использовать M, а не создавать новые

**G (Goroutine)**:

- Количество G может быть от единиц до миллионов
- Типичные приложения могут иметь от десятков до тысяч горутин
- Высоконагруженные серверные приложения могут иметь сотни тысяч горутин
- Теоретически, ограничено только доступной памятью

Соотношение:

- G >> M > P (гораздо больше горутин, чем потоков ОС, и немного больше потоков ОС, чем процессоров)
- Типичное соотношение может быть: P=8, M=10-20, G=1000-100000

Такое соотношение обеспечивает эффективное мультиплексирование большого количества горутин на ограниченное количество системных ресурсов.

## Как работают локальные и глобальная очереди горутин?

В Go планировщике существует два типа очередей для хранения готовых к выполнению горутин:

**Локальные очереди (Per-P Local Runqueue)**:

- Каждый P имеет собственную локальную очередь горутин
- Ограниченная емкость (256 горутин)
- Доступ без блокировок для "своего" M (lock-free)
- FIFO (first-in, first-out) порядок обработки
- Когда горутина создается, она обычно помещается в локальную очередь создавшего её P
- При заполнении локальной очереди половина горутин перемещается в глобальную очередь
- Оптимизирована для быстрого доступа и кэш-локальности

**Глобальная очередь (Global Runqueue)**:

- Одна общая очередь для всех P
- Неограниченная емкость
- Доступ требует блокировок (защищена мьютексом)
- FIFO порядок обработки
- Используется для балансировки нагрузки между P
- Горутины попадают сюда при:
  - Переполнении локальных очередей
  - Блокирующих системных вызовах
  - Горутинах, которые были заблокированы, а затем разблокированы другим P

**Алгоритм выбора следующей горутины для выполнения на P**:

1. Проверить локальную очередь P
2. С некоторой периодичностью (1/61 раз) проверить глобальную очередь
3. Попытаться украсть горутины из локальных очередей других P (work stealing)
4. Проверить сетевой поллер (netpoller) на наличие разблокированных горутин
5. Проверить таймеры на наличие истекших

Эта двухуровневая система очередей обеспечивает хороший баланс между производительностью (быстрый доступ к локальным очередям) и справедливостью распределения нагрузки (через глобальную очередь и work stealing).

## Что такое "work stealing" в контексте планировщика Go?

Work stealing (кража работы) — это механизм балансировки нагрузки в планировщике Go, который позволяет незагруженным P (процессорам) забирать горутины из очередей других, более загруженных P.

**Принцип работы**:

1. Когда P не имеет горутин для выполнения в своей локальной очереди, он не остается бездействующим
2. Вместо этого P пытается "украсть" горутины из других источников в следующем порядке:
   - Из глобальной очереди (с определенной вероятностью, обычно 1/61)
   - Из локальных очередей других P
   - От netpoller (сетевые операции, ставшие готовыми)
   - От таймеров, которые истекли

**Алгоритм кражи из локальных очередей**:

1. Выбор "жертвы" — случайно выбирается другой P
2. Попытка захватить блокировку на его очереди (если не удается, выбирается другая "жертва")
3. Кража половины горутин из очереди жертвы (но не более чем 1/2 от размера очереди)
4. Перемещение украденных горутин в свою локальную очередь

**Преимущества work stealing**:

- Автоматическая балансировка нагрузки между P
- Минимизация простоев процессорных ядер
- Улучшение локальности данных (горутины часто работают с похожими данными)
- Снижение конкуренции за глобальную очередь
- Адаптивность к различным паттернам нагрузки

**Особенности реализации**:

- Приоритет отдается локальной очереди для улучшения локальности кэша
- Кража выполняется из конца очереди "жертвы", а выполнение — из начала собственной очереди (работа LIFO)
- Процесс кражи не требует остановки "жертвы" (обычно блокируется только очередь)

Work stealing — ключевой механизм, обеспечивающий эффективную утилизацию CPU при неравномерной нагрузке на горутины.

## Как планировщик Go обрабатывает блокирующие системные вызовы?

Планировщик Go использует специальный механизм для обработки блокирующих системных вызовов, чтобы не блокировать P (Processor) при блокировке потока M (Machine):

**Процесс обработки блокирующего системного вызова**:

1. Горутина G выполняет блокирующий системный вызов
2. Runtime обнаруживает, что происходит блокирующий вызов
3. M отсоединяется от P, сохраняя при этом связь с G
4. P освобождается и может быть связан с другим потоком M для выполнения других горутин
5. Если нет свободных потоков M, создается новый поток M для работы с освободившимся P
6. Исходный поток M блокируется в ОС, ожидая завершения системного вызова
7. Когда системный вызов завершается:
   - Горутина G помечается как выполнимая
   - Если доступен свободный P, M пытается получить его и продолжить выполнение G
   - Если свободного P нет, G помещается в глобальную очередь, а M возвращается в пул или засыпает

**Оптимизации для часто используемых системных вызовов**:

1. **Сетевые операции**:
   - Используется netpoller для неблокирующего I/O
   - Вместо блокирующих системных вызовов используются асинхронные события (epoll/kqueue/IOCP)
   - Горутина паркуется, а не блокирует M
   - Когда операция завершается, горутина помещается обратно в очередь

2. **Таймеры и ожидания**:
   - Реализованы через центральный механизм таймеров
   - Горутина паркуется, а не блокирует M

3. **Особенности реализации**:
   - Системные вызовы помечаются специальными аннотациями для компилятора
   - Runtime перехватывает вызовы и выполняет подготовительные действия
   - Горутина помещается в специальное состояние (_Gsyscall)

Этот механизм гарантирует, что даже при большом количестве блокирующих системных вызовов остальные горутины продолжат выполняться эффективно, без чрезмерного создания потоков ОС.

## Как связаны переменная GOMAXPROCS и компонент P?

Переменная GOMAXPROCS и компонент P (Processor) в планировщике Go тесно связаны:

**Определение GOMAXPROCS**:

- GOMAXPROCS определяет максимальное количество P в программе
- Это значение ограничивает степень параллелизма выполнения (количество одновременно выполняемых горутин)
- По умолчанию с Go 1.5+ равно количеству логических CPU (ядер) в системе
- Может быть изменено через:
  - Переменную окружения GOMAXPROCS
  - Функцию runtime.GOMAXPROCS()

**Связь с компонентом P**:

1. **Количество P**:
   - При запуске Go-программы создается ровно GOMAXPROCS экземпляров P
   - Каждый P представляет собой виртуальный процессор с собственными ресурсами
   - В любой момент времени может быть активно не более GOMAXPROCS горутин

2. **Влияние на выполнение**:
   - P — это ресурс, необходимый для выполнения горутины
   - Горутина G выполняется потоком M только если доступен P
   - Увеличение GOMAXPROCS увеличивает параллелизм, но также увеличивает конкуренцию за ресурсы

3. **Динамическое изменение**:
   - При вызове runtime.GOMAXPROCS() во время выполнения:
     - Если новое значение больше — создаются дополнительные P
     - Если новое значение меньше — лишние P уничтожаются, а их горутины перемещаются
   - Изменение GOMAXPROCS требует кратковременной остановки планировщика

4. **Оптимальное значение**:
   - Для CPU-bound задач оптимальное значение обычно равно числу физических ядер
   - Для I/O-bound задач может быть эффективно установить большее значение
   - Слишком большое значение может ухудшить производительность из-за конкуренции за ресурсы

5. **Особенности**:
   - Даже при GOMAXPROCS=1 программа остается многопоточной (для обработки блокирующих вызовов)
   - GOMAXPROCS не влияет напрямую на количество потоков M (оно может быть больше)

Правильная настройка GOMAXPROCS критична для оптимальной производительности Go-программ, особенно в высоконагруженных системах или на машинах с большим количеством ядер.

## Что такое сетевой поллер (netpoller) и как он взаимодействует с планировщиком?

Сетевой поллер (netpoller) — это компонент Go Runtime, обеспечивающий эффективную обработку сетевых и других I/O операций без блокировки OS-потоков:

**Основные функции netpoller**:

- Управление неблокирующими сетевыми операциями
- Мультиплексирование множества I/O запросов на один поток ОС
- Уведомление планировщика о готовности данных

**Как работает netpoller**:

1. Использует оптимальный механизм асинхронного I/O для каждой ОС:
   - Linux: epoll
   - macOS/BSD: kqueue
   - Windows: I/O Completion Ports (IOCP)
   - Fallback: poll или select

2. **Процесс обработки сетевого I/O**:
   - Когда горутина выполняет сетевой вызов (чтение/запись), netpoller регистрирует интерес к событию
   - Если операция не может быть выполнена немедленно (нет данных для чтения или буфер записи полон)
   - Горутина паркуется (переходит в состояние _Gwaiting) и освобождает M и P
   - Netpoller отслеживает состояние сокета через механизм ОС
   - Когда сокет становится готовым, netpoller помечает горутину как выполнимую
   - Планировщик впоследствии выбирает эту горутину для выполнения

**Взаимодействие с планировщиком**:

1. **Интеграция в цикл планировщика**:
   - Планировщик периодически проверяет netpoller на наличие разблокированных горутин
   - При отсутствии работы планировщик может блокироваться в netpoller
   - При появлении новых событий поток разблокируется

2. **Горутина netpoller**:
   - Специальная системная горутина (в некоторых реализациях) мониторит асинхронные события
   - Работает в отдельном потоке M без P
   - Взаимодействует с планировщиком через легковесные примитивы синхронизации

3. **Поиск работы**:
   - Когда P ищет работу и локальные очереди пусты, проверяется наличие разблокированных горутин в netpoller
   - Разблокированные горутины получают приоритет перед кражей работы

**Преимущества подхода**:

- Эффективное использование ресурсов: один поток может обрабатывать тысячи соединений
- Отсутствие блокировки OS-потоков на I/O операциях
- Масштабируемость: возможность обработки большого количества одновременных соединений
- Низкая латентность переключения между горутинами

Благодаря netpoller, Go может эффективно работать с десятками тысяч одновременных соединений без создания соответствующего количества OS-потоков, что делает его идеальным для высоконагруженных сетевых приложений.

## Какие эвристики использует планировщик для балансировки нагрузки?

Планировщик Go использует различные эвристики для эффективной балансировки нагрузки между P (процессорами) и M (потоками ОС):

**1. Work Stealing (кража работы)**:

- Когда P остается без работы, он пытается "украсть" горутины из других источников:
  - С вероятностью 1/61 сначала проверяется глобальная очередь
  - Затем случайно выбирается другой P, и половина его горутин перемещается
- Обеспечивает равномерное распределение работы между процессорами

**2. Периодическая проверка глобальной очереди**:

- Каждый P проверяет глобальную очередь с периодичностью 1/61 операции планирования
- Гарантирует, что горутины из глобальной очереди не будут голодать

**3. Балансировка при создании горутин**:

- При создании новой горутины командой `go func()`:
  - Если локальная очередь P не заполнена, горутина помещается туда
  - Если локальная очередь заполнена, половина горутин перемещается в глобальную очередь
- Предотвращает скопление всех горутин на одном P

**4. Обработка блокирующих системных вызовов**:

- При блокирующем системном вызове:
  - M отсоединяется от P
  - P освобождается для других M
  - Если доступны М в состоянии простоя, они связываются с освободившимся P
  - Если нет, создается новый М
- Позволяет поддерживать уровень параллелизма при блокирующих операциях

**5. Сканирование бездействующих P**:

- Если P имеет горутины, но не выполняется на M, планировщик пытается найти простаивающий M или создать новый
- Обеспечивает, что готовые к выполнению горутины не будут ждать

**6. Системный монитор (sysmon)**:

- Фоновая горутина, которая периодически:
  - Проверяет долго выполняющиеся горутины (потенциальное вытеснение)
  - Возвращает в пул неиспользуемые M
  - Обрабатывает истекшие таймеры
  - Обнаруживает заблокированные goroutines на M и перераспределяет P

**7. Приоритизация новых горутин**:

- Недавно созданные или разблокированные горутины часто помещаются в начало локальной очереди
- Обеспечивает лучшую локальность кэша и более быстрый отклик

**8. Контроль создания потоков М**:

- Создание новых М ограничено (обычно максимум 10000)
- Повторное использование М из пула простаивающих
- Постепенное увеличение количества М при необходимости
- Освобождение излишних М при низкой нагрузке

Эти эвристики в совокупности обеспечивают хороший баланс между эффективным использованием ресурсов, минимизацией конкуренции и поддержанием высокой пропускной способности для различных типов нагрузки.

## Как реализовано вытеснение горутин? Как оно изменилось с версии Go 1.14?

Вытеснение горутин в Go прошло значительную эволюцию, особенно с версии 1.14:

**До Go 1.14: Кооперативное вытеснение**

В ранних версиях Go использовалось только кооперативное вытеснение, когда горутина могла быть прервана только в определенных точках:

1. **Точки вытеснения**:
   - Вызовы функций (компилятор вставлял проверки планировщика)
   - Операторы `for` (в некоторых случаях)
   - Барьеры памяти GC
   - Явные вызовы runtime.Gosched()

2. **Проблемы**:
   - "Злонамеренные" горутины с CPU-bound циклами могли блокировать выполнение других горутин
   - Задержки сборки мусора из-за невозможности прервать все горутины
   - Непредсказуемость времени отклика в нагруженных системах

**С Go 1.14: Асинхронное вытеснение**

В Go 1.14 было добавлено асинхронное вытеснение, позволяющее прерывать выполнение горутины в любой момент:

1. **Механизм реализации**:
   - Использование сигналов ОС (SIGURG на Unix-системах)
   - Системный монитор (sysmon) периодически отправляет сигналы потокам M с долго выполняющимися горутинами
   - Обработчик сигнала проверяет, требуется ли вытеснение (GC или долгое выполнение)
   - При необходимости вытеснения горутина помечается для перепланирования

2. **Когда происходит вытеснение**:
   - При необходимости запуска сборки мусора (GC)
   - Когда горутина выполняется слишком долго (обычно >10мс)
   - При необходимости балансировки нагрузки

3. **Ограничения асинхронного вытеснения**:
   - В ранних версиях не работало для кода, скомпилированного без отладочной информации
   - Не работает для кода на ассемблере
   - CGO-вызовы не могут быть вытеснены асинхронно

**Основные изменения с Go 1.14**:

1. **Добавление асинхронного вытеснения**:
   - Возможность прерывать горутины в произвольных точках
   - Использование сигналов SIGURG для доставки запроса на вытеснение
   - Добавление проверок в обработчик сигналов

2. **Улучшения в Go 1.15+**:
   - Оптимизация механизма доставки сигналов
   - Улучшенная интеграция с GC
   - Более точное определение долго выполняющихся горутин

3. **Алгоритм вытеснения**:
   - Системный монитор отслеживает горутины, выполняющиеся дольше порогового значения
   - Отправляет сигнал соответствующему потоку M
   - Обработчик сигнала устанавливает флаг вытеснения для горутины
   - При первой возможности горутина прерывается и возвращается в очередь планировщика

4. **Безопасность вытеснения**:
   - Предотвращение вытеснения в критических секциях runtime
   - Защита от вытеснения при работе с нерекурсивными мьютексами

Асинхронное вытеснение значительно улучшило поведение Go в ситуациях с интенсивными вычислениями, сделав время отклика более предсказуемым и улучшив работу GC.
