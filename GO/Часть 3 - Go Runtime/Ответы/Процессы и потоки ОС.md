# Ответы: Процессы и потоки ОС

## В чем разница между процессом и потоком в операционной системе?

Процесс — это экземпляр выполняющейся программы с выделенными ресурсами, имеющий собственное адресное пространство. Поток — это единица выполнения внутри процесса, разделяющая адресное пространство процесса, но имеющая свой стек и регистры. Основные различия:

- Процесс имеет собственное изолированное адресное пространство, потоки одного процесса разделяют это пространство.
- Процессы имеют свои файловые дескрипторы, потоки разделяют эти ресурсы.
- Создание процесса требует больше ресурсов и времени, чем создание потока.
- Переключение между процессами обычно дороже, чем между потоками одного процесса.
- Процессы взаимодействуют через IPC-механизмы, потоки могут напрямую использовать общую память.

## Что включает в себя адресное пространство процесса?

Адресное пространство процесса включает:

1. Сегмент кода (text) — содержит исполняемые инструкции, обычно read-only.
2. Сегмент данных (data) — инициализированные глобальные и статические переменные.
3. Сегмент BSS — неинициализированные глобальные и статические переменные.
4. Куча (heap) — динамически выделяемая память, расширяется вверх.
5. Стек (stack) — локальные переменные, аргументы функций, адреса возврата, расширяется вниз.
6. Пространство для подключаемых библиотек — динамические библиотеки (DLL/shared objects).
7. Системные страницы — зарезервированные области памяти для использования ОС.

Все это организовано в виртуальное адресное пространство, которое отображается на физическую память через страничные таблицы.

## Какие ресурсы разделяют потоки внутри одного процесса, а какие имеют собственные?

**Разделяемые ресурсы**:

- Адресное пространство (код, данные, куча)
- Глобальные переменные
- Файловые дескрипторы и сокеты
- Рабочий каталог и переменные окружения
- Сигналы и обработчики сигналов
- Дескрипторы памяти и отображаемых файлов
- Код программы
- Права доступа и аутентификация

**Собственные ресурсы потока**:

- Стек выполнения
- Набор регистров процессора
- Счетчик команд (PC — Program Counter)
- TID (идентификатор потока)
- Локальное хранилище потока (Thread Local Storage, TLS)
- Состояние ошибок (errno в POSIX)
- Приоритет планирования
- Маска блокировки сигналов

## Как работает планировщик ОС? Какие стратегии планирования существуют?

Планировщик ОС отвечает за распределение процессорного времени между потоками. Основные стратегии планирования:

1. **Циклическое планирование (Round-robin)** — каждый поток получает равный квант времени в циклическом порядке.
2. **Планирование по приоритетам** — потокам назначаются приоритеты, высокоприоритетные выполняются в первую очередь.
3. **Многоуровневые очереди с обратной связью (Multilevel feedback queue)** — динамическое изменение приоритетов потоков в зависимости от их поведения.
4. **Планирование в реальном времени** — гарантированное выполнение в заданные временные рамки.
5. **Планирование с полностью справедливым разделением времени (Completely Fair Scheduler)** — используется в Linux, стремится предоставить справедливое процессорное время всем потокам.

Современные ядра обычно используют гибридные алгоритмы, сочетающие различные стратегии для разных классов задач.

## Что такое квант времени и прерывание таймера в контексте планирования?

Квант времени — это максимальное непрерывное время выполнения, выделяемое потоку перед принудительным переключением. Прерывание таймера — это аппаратное прерывание, генерируемое по истечении кванта времени, которое позволяет ОС перехватить управление и выполнить планировщик.

Процесс работы с квантами времени:

1. Планировщик выбирает поток и устанавливает таймер на определенный квант.
2. По истечении кванта происходит прерывание таймера.
3. Обработчик прерывания сохраняет состояние текущего потока.
4. Планировщик выбирает следующий поток для выполнения.
5. Загружается контекст нового потока, и он начинает выполняться.

Размер кванта времени варьируется в зависимости от ОС и настроек, обычно это от нескольких миллисекунд до десятков миллисекунд.

## Что представляет собой переключение контекста (context switching) и какова его стоимость?

Переключение контекста — это процесс сохранения состояния выполняющегося потока и загрузки состояния другого потока. Включает:

**Что сохраняется**:

- Значения регистров процессора
- Счетчик команд (PC)
- Указатель стека (SP)
- Указатель на страничные таблицы
- Состояние FPU (блока с плавающей точкой)
- Другие архитектурно-зависимые регистры

**Стоимость переключения контекста**:

- **Прямые затраты**: время выполнения инструкций сохранения/восстановления (~1-10 мкс между потоками одного процесса, ~10-100 мкс между разными процессами).
- **Непрямые затраты**: инвалидация кэшей процессора, TLB (Translation Lookaside Buffer), что может значительно снизить производительность после переключения.

Факторы, влияющие на стоимость:

- Аппаратная поддержка переключения контекста
- Размер рабочего набора потока (working set)
- Количество регистров в архитектуре
- Эффективность реализации планировщика

## Какие механизмы межпроцессного взаимодействия (IPC) существуют?

Основные механизмы IPC:

1. **Файлы и файловая система** — простейший способ обмена данными
2. **Сигналы** — асинхронные уведомления, отправляемые процессу
3. **Пайпы (pipes)** — однонаправленные каналы передачи данных
   - Безымянные пайпы (`|` в командной строке)
   - Именованные пайпы (FIFOs) — двунаправленные каналы с именем в файловой системе
4. **Сокеты** — конечные точки двунаправленной коммуникации
   - Unix-сокеты (для локального взаимодействия)
   - Сетевые сокеты (для сетевого взаимодействия)
5. **Разделяемая память** — область памяти, доступная нескольким процессам
6. **Очереди сообщений** — буферизованный обмен сообщениями
7. **Семафоры и мьютексы** — примитивы синхронизации
8. **RPC (Remote Procedure Call)** — вызов процедур в другом адресном пространстве
9. **Отображаемые в память файлы** — файлы, отображенные в адресное пространство процесса
10. **Передача дескрипторов** — передача файловых дескрипторов между процессами

Выбор механизма зависит от требований к производительности, объему передаваемых данных и нужной семантики взаимодействия.

## Как организована виртуальная память процессов?

Виртуальная память организована как абстракция, скрывающая физическую память и позволяющая каждому процессу иметь собственное непрерывное адресное пространство. Ключевые аспекты:

1. **Страничная организация** — виртуальная память разделена на страницы (обычно 4 КБ), которые могут быть загружены в физическую память или выгружены на диск.
2. **Страничные таблицы** — структуры данных, отображающие виртуальные адреса на физические.
3. **TLB (Translation Lookaside Buffer)** — кэш для быстрого преобразования виртуальных адресов в физические.
4. **Подкачка (swapping)** — механизм выгрузки редко используемых страниц на диск и загрузки необходимых.
5. **Защита памяти** — каждая страница имеет атрибуты доступа (чтение/запись/выполнение).
6. **Разделяемые страницы** — позволяют нескольким процессам использовать одну физическую страницу (например, для кода библиотек).
7. **Ленивое выделение (lazy allocation)** — физическая память выделяется только при фактическом доступе к странице.

Современные процессоры имеют аппаратную поддержку виртуальной памяти через MMU (Memory Management Unit).

## Что такое потоки пользовательского уровня и потоки ядра? В чем их отличия?

**Потоки пользовательского уровня (user-level threads)**:

- Управляются в пользовательском пространстве библиотекой потоков
- ОС не знает о них и видит только один поток ядра
- Быстрое создание и переключение
- Не могут использовать многоядерность
- Блокировка одного потока блокирует весь процесс

**Потоки ядра (kernel-level threads)**:

- Управляются непосредственно ядром ОС
- ОС планирует каждый поток индивидуально
- Более дорогие для создания и переключения
- Могут выполняться параллельно на разных ядрах
- Блокировка одного потока не блокирует другие потоки

**Гибридная модель (M:N threading)**:

- Множество потоков пользовательского уровня отображаются на меньшее количество потоков ядра
- Сочетает преимущества обоих подходов
- Используется в Go (горутины отображаются на потоки ОС)
- Более сложная реализация, но лучшая масштабируемость

## Как связаны процессы и потоки ОС с моделью выполнения Go?

Go использует гибридную модель M:N, где:

1. **Go-программа выполняется как один процесс ОС** (за исключением случаев с явным созданием дочерних процессов).
2. **Go Runtime управляет горутинами**, которые являются легковесными потоками пользовательского уровня.
3. **Модель GMP**:
   - G (Goroutine) — горутины, которых может быть тысячи или миллионы
   - M (Machine) — потоки ОС, обычно не больше GOMAXPROCS + некоторое количество для блокирующих операций
   - P (Processor) — абстракция, связывающая G и M, количество ограничено GOMAXPROCS
4. **Go Scheduler** работает в пользовательском пространстве и планирует горутины на потоки, минимизируя переключения контекста на уровне ОС.
5. **Блокирующие системные вызовы** обрабатываются особым образом: поток M отсоединяется от P, позволяя другим горутинам продолжать выполнение на этом P.
6. **Сетевые операции** обрабатываются через netpoller, который использует неблокирующий I/O и события ОС для минимизации использования потоков.

Эта модель обеспечивает высокую эффективность и масштабируемость, позволяя запускать миллионы горутин с минимальными накладными расходами.
